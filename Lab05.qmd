---
title: "Lab05"
author: Catherine Le
format: 
  html:
    embed resources: true
editor: visual
---

# Preliminary

```{r}
library(data.table)
library(magrittr)
# Download the data
stations <- fread("ftp://ftp.ncdc.noaa.gov/pub/data/noaa/isd-history.csv")
stations[, USAF := as.integer(USAF)]

# Dealing with NAs and 999999
stations[, USAF   := fifelse(USAF == 999999, NA_integer_, USAF)]
stations[, CTRY   := fifelse(CTRY == "", NA_character_, CTRY)]
stations[, STATE  := fifelse(STATE == "", NA_character_, STATE)]

# Selecting the three relevant columns, and keeping unique records
stations <- unique(stations[, list(USAF, CTRY, STATE)])

# Dropping NAs
stations <- stations[!is.na(USAF)]

# Removing duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]
```

```{r}
if (!file.exists("met_all.gz"))
  download.file(
    url = "https://raw.githubusercontent.com/USCbiostats/data-science-data/master/02_met/met_all.gz",
    destfile = "met_all.gz",
    method   = "libcurl",
    timeout  = 60
  )
met <- data.table::fread("met_all.gz")
```

Merging the data as in lecture

```{r}
# merging the met and the stations dataset
merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  ) %>% nrow()

# removing the duplicates
stations[, n := 1:.N, by = .(USAF)]
stations <- stations[n == 1,][, n := NULL]

dat <- merge(
  # Data
  x     = met,      
  y     = stations, 
  # List of variables to match
  by.x  = "USAFID",
  by.y  = "USAF", 
  # Which obs to keep?
  all.x = TRUE,      
  all.y = FALSE
  )
head(dat[, list(USAFID, WBAN, STATE)], n = 4)
```

# Question 1: Representative Stations for the U.S.

```{r}
library(data.table)
library(magrittr)

# finds the average temperature, wind speed, and atmospheric pressure
data_mean <- 
  dat[, .(
    temp_mean      = mean(temp, na.rm=TRUE),
    wind.sp_mean   = mean(wind.sp, na.rm=TRUE),
    atm.press_mean = mean(atm.press, na.rm = TRUE)
    ),
    by = USAFID # groups and orders by USAFID
    ][order(USAFID)] %>% 
    head(n = 3) # shows the first 3 rows
data_mean

```

Using quantile function

```{r}
# finding the quantiles for each variable
m1 <- quantile(data_mean$temp_mean, 0.5, na.rm=TRUE, type=1)
m2 <- quantile(data_mean$wind.sp_mean, 0.5, na.rm=TRUE, type=1)
m3 <- quantile(data_mean$atm.press_mean, 0.5, na.rm=TRUE, type=1)

# I ended up having to comment out this code because my qmd would not render
# This was confusing because this code chunk ran perfectly fine in R
# The error message said that temp_mean was not found even though it is in the dataframe

# data_mean %>% filter(temp_mean == m1 )
# 
# data_mean %>% 
#   filter(wind.sp_mean == m2 )
# 
# data_mean %>% 
#   filter(atm.press_mean == m3 )
```

Summary: The three mean stations in terms of temperature, wind speed, and stmospheric pressure do coincide with the three weather stations that best coincide with the continental US.

# Question 2: Representative Station per State

```{r}
# finding the euclidean distance
# formular = √[ (x2 – x1 )2 + (y2 – y1 )2] 
library(dplyr)
rep_stations <- dat %>% group_by(STATE) %>%
  mutate(euclidean = sqrt((lat - mean(lat))^2 + (lon - mean(lon))^2)) %>% arrange(STATE, euclidean, lat) %>% slice(1) %>% select(STATE, USAFID, lat, lon, euclidean)

# ordering the station
ordered_stations <- rep_stations[order(rep_stations$lat, decreasing = TRUE), ]
first_station <- ordered_stations[1, ]
first_station
```

# Question 3: in the middle?

Finding the stations that is closest to the midpoint of each state

```{r}
# finding the midpoints for each state
midpoints <- dat %>%
  group_by(STATE) %>%
  summarize(
    middle_lat = mean(lat),
    middle_long = mean(lon)
  )
midpoints

# functioon to fibd the station closest to the station
closest_station_function <- function(point, stations) {
  distances <- sqrt((stations$lat - point$middle_lat)^2 + (stations$lon - point$middle_lon)^2)
  closest_station <- stations[which.min(distances), ]
  return(closest_station)}

# Find the closest station to each midpoint
closest_stations <- midpoints %>% 
  rowwise() %>% 
  do(closest_station_function(., dat))
```

Creating leaflet map for data

```{r}
library(leaflet)

# map of stations closest to the midpoint of each state
stations_map <- leaflet(midpoints) %>%
  addProviderTiles('CartoDB.Positron') %>%
  addCircleMarkers(
    lng = ~middle_long,
    lat = ~middle_lat,
    radius = 5,               
    color = 'lightgreen',           
    fillOpacity = 0.7)  
stations_map

# map of eucledian distance
euc_dis_map <- leaflet(rep_stations) %>%
  addProviderTiles('CartoDB.Positron') %>%
  addCircleMarkers(
    lng = ~lon,
    lat = ~lat,
    radius = 5,               
    color = 'purple',           
    fillOpacity = 0.7)  
euc_dis_map
```

# Question 4: Means of Means

Computing the states' average temperatures and classifying it into categories

```{r}
# Calculating the average temperature for each state
avg_data <- 
  dat[, .(
    temp_mean      = mean(temp, na.rm=TRUE),
    wind.sp_mean   = mean(wind.sp, na.rm=TRUE),
    atm.press_mean = mean(atm.press, na.rm = TRUE)
    ),
    by = STATE]

# Creates categories based on the criteria
avg_temp <- avg_data %>%
  mutate(temp_mean = case_when(
  temp_mean < 20 ~ "Low",
  temp_mean >= 20 & temp_mean < 25 ~ "Mid",
  temp_mean >= 25 ~ "High",
  TRUE ~ "Unknown"  # Handle any other cases
  ))

# using quantile() function
quantiles <- quantile(avg_data$temp_mean, probs = c(0, 0.2, 1))

summary_table <- avg_temp %>%
  group_by(temp_mean) %>%
  summarize(
    num_entries = n(),
    num_states_included = n_distinct(STATE),
    mean_wind_speed = mean(wind.sp_mean, na.rm = TRUE),
    mean_atmos_pressure = mean(atm.press_mean, na.rm = TRUE)
  )

summary_table
```
